import torch
import cv2
import time
import math
import aiohttp
import asyncio
import numpy as np
from ultralytics import YOLO
from onvif import ONVIFCamera
from db_operations import insert_frame
from db_pool import close_connection_pool  # ì¢…ë£Œ ì‹œ ì»¤ë„¥ì…˜ í’€ ë‹«ê¸°

SERVER_URL = "http://localhost:7800"
BEARER_TOKEN = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJvcmdfaWQiOiIyNSIsIm9yZ19ncm91cF9pZCI6ImRlNTNhNzIyLTkzNDMtNDllMC1hMmVlLTQ0ZWFjNjlhZmU1NiIsIm5hbWUiOiJ1bml2cyIsImVtYWlsIjoia3R5QHVuaXZzLmFpIiwiaWF0IjoxNzM2Mzk1NDc5LCJleHAiOjM0NzI3OTA5NTh9.XzxfCy3V0wc8MpYO6m6LvT98UESKOrMXayITTJdncpA"

# ë¹„ë™ê¸° HTTP ìš”ì²­ í•¨ìˆ˜
async def send_frame_async(image_data):
    headers = {"Authorization": f"Bearer {BEARER_TOKEN}"}
    
    async with aiohttp.ClientSession(headers=headers) as session:
        async with session.post(SERVER_URL, data={'image': image_data}) as response:
            result = await response.text()
            return f"ğŸ“¡ ì„œë²„ ì‘ë‹µ: {response.status}, {result}"

# ë¹„ë™ê¸° HTTP ìš”ì²­ í•¨ìˆ˜
async def send_human_async(image_data, rect):
    headers = {"Authorization": f"Bearer {BEARER_TOKEN}"}
    
    async with aiohttp.ClientSession(headers=headers) as session:
        async with session.post(SERVER_URL+ "/event/generate", data={'image': image_data}) as response:
            result = await response.text()
            return f"ğŸ“¡ ì„œë²„ ì‘ë‹µ: {response.status}, {result}"
        
# ë¹„ë™ê¸° HTTP ìš”ì²­ í•¨ìˆ˜
async def send_vehicle_async(image_data, rect):
    headers = {"Authorization": f"Bearer {BEARER_TOKEN}"}
    
    async with aiohttp.ClientSession(headers=headers) as session:
        async with session.post(SERVER_URL + "/bestframe/vehicle", data={'image': image_data}) as response:
            result = await response.text()
            return f"ğŸ“¡ ì„œë²„ ì‘ë‹µ: {response.status}, {result}"        


frame_skip = 30

ip = '192.168.0.100'  # ì¹´ë©”ë¼ IP
port = 80             # ONVIF ì„œë¹„ìŠ¤ í¬íŠ¸ (ë³´í†µ 80, 8080 ë“±)
user = 'admin'        # ONVIF ê³„ì •
passwd = 'admin'      # ONVIF ê³„ì • ë¹„ë°€ë²ˆí˜¸



def is_overlapping_with_center_offset(rect1, rect2):
    # rect1ì˜ ì¤‘ì‹¬ì¢Œí‘œ ê³„ì‚°
    x1_c = (rect1[0] + rect1[2]) / 2
    y1_c = (rect1[1] + rect1[3]) / 2

    # rect2ì˜ ì¤‘ì‹¬ì¢Œí‘œ ê³„ì‚°
    x2_c = (rect2[0] + rect2[2]) / 2
    y2_c = (rect2[1] + rect2[3]) / 2

    vehicle_w = rect2[2] - rect2[0] / 2

    # ë‘ ì‚¬ê°í˜• ì¤‘ì‹¬ ê°„ ê±°ë¦¬ ê³„ì‚° (ìœ í´ë¦¬ë“œ ê±°ë¦¬)
    distance = math.sqrt((x2_c - x1_c) ** 2 + (y2_c - y1_c) ** 2)
    return distance < vehicle_w 

async def main():
    model = YOLO('yolo11n.pt', verbose=False)  # COCO ì‚¬ì „ í•™ìŠµ
    model.overrides['conf'] = 0.25  # confidence threshold ì„¤ì •

    if torch.cuda.is_available():
        model.to('cuda')
        print("GPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    else:
        print("GPUê°€ ì—†ì–´ì„œ CPUë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
    
    # 3. ì›¹ìº  ì—´ê¸° (0ë²ˆ ì¥ì¹˜)
    cap = cv2.VideoCapture("sample.webm")
    if not cap.isOpened():
        print(".")
        return

    raw_frame = 0
    current_frame = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            print(".")
            break
        
        if raw_frame % frame_skip == 0:
            results = model.predict(frame)
            clone_frame = frame.copy()
            
            tasks = []            
            vehicles = []
            humans = []
            for r in results:
                object_idx = 1
                            
            
                for box in r.boxes:
                    cls_id = int(box.cls[0])
                    conf = float(box.conf[0])
                    label = model.names[cls_id]  # COCO í´ë˜ìŠ¤ëª…
                    xyxy = box.xyxy[0].cpu().numpy().astype(int)  # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ
                 
                    # "person", "car"ë§Œ í•„í„°ë§
                    if label in ["person", "car"]:
                        x1, y1, x2, y2 = xyxy

                        # if label == "person":
                        #     persons.append({
                        #         "object_type": label,
                        #         "rect": (x1, y1, x2, y2)
                        #     })

                        # if label == "car":
                        #     cars.append({
                        #         "object_type": label,
                        #         "rect": (x1, y1, x2, y2)
                        #     })


                        cropped_frame = clone_frame[y1:y2, x1:x2]
                        _, img_encoded = cv2.imencode('.jpg', cropped_frame)
                        
                        if label == "car":
                            tasks.append(send_vehicle_async(img_encoded.tobytes(), (x1, y1, x2, y2)))
                        if label == "person":
                            tasks.append(send_human_async(img_encoded.tobytes(), (x1, y1, x2, y2)))


                        cv2.rectangle(frame, (x1, y1), (x2, y2), (255,0,0), 2)
                        cv2.putText(frame, f"{label}", 
                                    (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 
                                    0.6, (0,255,0), 2)                    

                    object_idx += 1   
                
                # for person in persons:
                #     for car in cars:
                #         print("Person overlap + " + str(is_overlapping_with_center_offset(person['rect'], car['rect'])))
            results = await asyncio.gather(*tasks)

            # ê²°ê³¼ ì¶œë ¥
            for res in results:
                print(res)
        


        if raw_frame % frame_skip == 0:
            # filename = "./frames/frame_" + str(current_frame) + ".jpg"
            _, img_encoded = cv2.imencode('.jpg', frame)
            # ë¹„ë™ê¸° HTTP ìš”ì²­ ì‹¤í–‰ (ì„œë²„ ì‘ë‹µì„ ê¸°ë‹¤ë¦¬ì§€ ì•ŠìŒ)
            send_frame_async(img_encoded.tobytes())

            current_frame += 1

        # cv2.imshow("YOLOv11n - Person & Car", frame)        
        raw_frame += 1
       
        if cv2.waitKey(1) & 0xFF == 27:  # ESC ì¢…ë£Œ
            break

    cap.release()
    cv2.destroyAllWindows()

asyncio.run(main())